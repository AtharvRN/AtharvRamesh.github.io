<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Atharv Ramesh · Research</title>
  <meta name="description" content="Research experience and projects by Atharv Ramesh." />
  <link rel="stylesheet" type="text/css" href="style.css" />
  <link rel="shortcut icon" type="image/png" href="assets/profile.png" />
</head>

<body>
  <div class="container">
    <header class="intro">
      <div>
        <h1>Research Experience</h1>
        <p class="contact"><a href="index.html">Back to home</a></p>
      </div>
    </header>

    <main>
      <section class="section">
        <article class="feature">
          <figure>
            <img src="images/dreamprm.png" alt="DreamPRM architecture diagram">
            <p class="caption">Image credit: DreamPRM authors (<a href="https://arxiv.org/pdf/2505.20241.pdf">source</a>)</p>
          </figure>
          <div>
            <h3>Test time Scaling for LLMs using Process Reward Models</h3>
            <p><a href="https://github.com/AtharvRN/refound_finetuning">GitHub [WIP]</a></p>
            <p>
              Building DreamPRM-style process reward models for Lean4 theorem proving: curate token-level feedback with symbolic checkers, LoRA-adapt Llama‑3.2 3B, and deploy inference-time reranking inside a Nautilus multi-GPU Kubernetes stack (PVC-mounted datasets, NCCL jobs, vLLM serving). The PRM gate boosts proof success by 9% while cutting search tokens ~17%, and the repo now packages reproducible manifests for future Lean PRM experiments.
            </p>
          </div>
        </article>

        <article class="feature">
          <figure>
            <img src="images/retfound.png" alt="RETFound OCT project visual">
          </figure>
          <div>
            <h3>OCT Analysis with RETFound &amp; Generative Augmentations</h3>
            <p class="meta">Biomedical vision · Generative modeling</p>
            <p><a href="https://doi.org/10.3390/bioengineering11121186">Publication</a> · <a href="https://github.com/AtharvRN/refound_finetuning">Code</a></p>
            <p>
              Extended RETFound’s masked-autoencoder foundation (pretrained on 1.6M CFP/OCT frames) to 1.8k noisy B-scans using AutoMorph, axial cropping, and 224px SSL augmentations. Fine-tuned task heads for multi-label biomarker detection (Acc 0.77 / AUC 0.80) and spun up Pix2Pix + latent diffusion pipelines that synthesize realistic OCT volumes, improving recall on rare pathologies and underpinning our Bioengineering 2024 paper.
            </p>
          </div>
        </article>

        <article class="feature">
          <figure>
            <img src="images/sp_cup.png" alt="Speaker verification competition presentation cover">
          </figure>
          <div>
            <h3>Far-Field Speaker Verification on Mobile Robots</h3>
            <p class="meta">IEEE SP Cup 2024 winners</p>
            <p><a href="https://github.com/AtharvRN/SP_CUP2024_Speaker_Verification">GitHub</a></p>
            <p>
              Shipped the ICASSP ’24 winning RoboVox pipeline by upgrading ERes2Net with attentive local/global fusion, 80-d log-mel features, and AAM-Softmax training. Blended VoxCeleb, CN-Celeb, and far-field 3D-Speaker corpora plus RIRS, MUSAN, and speed perturbations; scoring uses cosine similarity with adaptive s-norm to hit minDCF 0.67 / EER 8.93 across the mobile robot’s multi-channel microphone array.
            </p>
          </div>
        </article>
      </section>
    </main>
  </div>
</body>

</html>
