<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Atharv Ramesh</title>
  <meta name="description" content="Machine Learning engineer building reliable perception and language systems for edge devices and research workflows." />
  <link rel="stylesheet" type="text/css" href="style.css" />
  <link rel="shortcut icon" type="image/png" href="assets/profile.png" />
  <link href='https://fonts.googleapis.com/css?family=Nunito' rel='stylesheet'>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0">
      <td style="padding:0">
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr style="padding:0">
            <td style="padding:1.5%;width:70%;vertical-align:middle">
              <h1>Atharv Ramesh</h1>
              <p align='center'>atharv.ramesh2003@gmail.com · a3nair@ucsd.edu</p>
              <p>
                I am masters student at UC San Diego in the ECE Department specializing in Machine Learning and Data Science. I worked at
                <a href="https://www.netradyne.com/">Netradyne</a> as a Machine Learning Engineer, where I worked on edge ML systems for Advanced Driver Assistance Systems (ADAS) applications. I completed my bachelor's degree at
                <a href="https://iith.ac.in/">Indian Institute of Technology Hyderabad</a> in Electrical Engineering.
              <p>
                I just started grad school and am actively exploring research opportunities in LLMs and Computer Vision. I have recently started working on test time scaling of LLMs with process reward models.
                I am also looking to work on SOTA computer vision research problems. I am also actively looking for MLE/Research Intern roles for Summer 2026 and beyond.
              </p>
              <p style="text-align:center">
                <a href="Atharv_Ramesh_Resume.pdf">Resume</a>&nbsp;·&nbsp;
                <a href="https://github.com/AtharvRN">GitHub</a>&nbsp;·&nbsp;
                <a href="https://www.linkedin.com/in/Atharv-Ramesh">LinkedIn</a>&nbsp;·&nbsp;
                <a href="#projects">Projects</a>
              </p>
            </td>
            <td style="padding:3%;width:30%;max-width:30%">
              <img style="width:100%;max-width:100%" alt="Portrait of Atharv Nair" src="assets/profile.png">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:30px auto;" border="0">
          <tr>
            <td>
              <h2>Recent Updates</h2>
              <table class="news-table">
                <tr>
                  <td class="news-date">Sep 2025</td>
                  <td>Started my M.S. in Machine Learning and Data Science at UC San Diego (ECE).</td>
                </tr>
                <tr>
                  <td class="news-date">Dec 2024</td>
                  <td>Published my first paper in <a href="https://doi.org/10.3390/bioengineering11121186">Bioengineering</a>.</td>
                </tr>
                <tr>
                  <td class="news-date">June 2024</td>
                  <td>Graduated from IIT Hyderabad and starting as an Associate AI Engineer at Netradyne, Bengaluru, India.</td>
                </tr>
              </table>
            </td>
          </tr>

        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:30px auto 10px auto;" border="0">
          <tr>
            <td>
              <h2>Publications</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr>
            <td style="padding:15px 0">
              <strong>Detection of Disease Features on Retinal OCT Scans Using RETFound.</strong><br>
              K. Du, <strong>A. R. Nair</strong>, S. Shah, A. Gadari, S. C. Vupparaboina, J.-A. Sahel, et al.<br>
              <em>Bioengineering</em>, 2024.&nbsp;
              <a href="https://doi.org/10.3390/bioengineering11121186">DOI</a>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr>
            <td>
              <h2>Work Experience</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr>
            <td style="padding:20px 0;width:100%;vertical-align:top">
              <div class="experience-card">
                <h3>Netradyne</h3>
                <p class="experience-meta">Software Engineer — Machine Learning · Jun 2024 – Aug 2025 · Bengaluru, India</p>
                <ul>
                  <li>Re-architected the edge video stack with async scheduling and priority queues, delivering a 17% throughput gain with zero frame drops.</li>
                  <li>Deployed passenger safety, unsecured package, and drowsiness models across Qualcomm SNPE and NVIDIA TensorRT platforms.</li>
                  <li>Merged multi-service components into a multithreaded daemon, shaving 3% RAM and hardening cross-compilation and CI for fleet updates.</li>
                </ul>
              </div>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:100%;vertical-align:top">
              <div class="experience-card">
                <h3>Silicon Labs</h3>
                <p class="experience-meta">Software Engineer Intern · May 2023 – Jul 2023 · Hyderabad, India</p>
                <ul>
                  <li>Implemented Minstrel adaptive rate control on RS9116 Wi-Fi modules, improving rate-vs-range behavior in live field tests.</li>
                  <li>Worked across embedded C, Linux drivers, and IEEE 802.11 stack diagnostics for low-power IoT deployments.</li>
                </ul>
              </div>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:100%;vertical-align:top">
              <div class="experience-card">
                <h3>Alog Tech</h3>
                <p class="experience-meta">Robotics Software Developer · May 2023 – Jul 2023 · Hyderabad, India</p>
                <ul>
                  <li>Built a fully autonomous indoor navigation stack with ROS Navigation, custom planners, and watchdog services.</li>
                  <li>Integrated motor control interfaces and YOLO-based perception for reliable obstacle avoidance on mobile robots.</li>
                </ul>
              </div>
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:30px auto 10px auto;" border="0">
          <tr>
            <td>
              <h2 id="research">Research Experience</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/dreamprm.png" alt="DreamPRM architecture diagram" style="max-width:100%;">
              <p style="font-size:x-small;text-align:center;margin-top:4px;">Image credit: DreamPRM authors (<a href="https://arxiv.org/pdf/2505.20241.pdf">source</a>)</p>
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Test time Scaling for LLMs using Process Reward Models</h3><br>
              <em></em><br><br>
              <a href="https://github.com/AtharvRN/refound_finetuning">GitHub [WIP]</a>
              <p>
                Building DreamPRM-style process reward models for Lean4 theorem proving: curate token-level feedback with symbolic checkers, LoRA-adapt Llama‑3.2 3B, and deploy inference-time reranking inside a Nautilus multi-GPU Kubernetes stack (PVC-mounted datasets, NCCL jobs, vLLM serving). The PRM gate boosts proof success by 9% while cutting search tokens ~17%, and the repo now packages reproducible manifests for future Lean PRM experiments.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/retfound.png" alt="RETFound OCT project visual">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>OCT Analysis with RETFound &amp; Generative Augmentations</h3><br>
              <em>Biomedical vision · Generative modeling</em><br><br>
              <a href="https://doi.org/10.3390/bioengineering11121186">Publication</a>&nbsp;|&nbsp;
              <a href="https://github.com/AtharvRN/refound_finetuning">Code</a>
              <p>
                Extended RETFound’s masked-autoencoder foundation (pretrained on 1.6M CFP/OCT frames) to 1.8k noisy B-scans using AutoMorph, axial cropping, and 224px SSL augmentations. Fine-tuned task heads for multi-label biomarker detection (Acc 0.77 / AUC 0.80) and spun up Pix2Pix + latent diffusion pipelines that synthesize realistic OCT volumes, improving recall on rare pathologies and underpinning our Bioengineering 2024 paper.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/sp_cup.png" alt="Speaker verification competition presentation cover">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Far-Field Speaker Verification on Mobile Robots</h3><br>
              <em>IEEE SP Cup 2024 winners</em><br><br>
              <a href="https://github.com/AtharvRN/SP_CUP2024_Speaker_Verification">GitHub</a>
              <p>
                Shipped the ICASSP ’24 winning RoboVox pipeline by upgrading ERes2Net with attentive local/global fusion, 80-d log-mel features, and AAM-Softmax training. Blended VoxCeleb, CN-Celeb, and far-field 3D-Speaker corpora plus RIRS, MUSAN, and speed perturbations; scoring uses cosine similarity with adaptive s-norm to hit minDCF 0.67 / EER 8.93 across the mobile robot’s multi-channel microphone array.
              </p>
            </td>
          </tr>
          <!-- Add Cosmic Ray Segmentation here if available -->
        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin:30px auto 10px auto;" border="0">
          <tr>
            <td>
              <h2 id="projects">Selected Projects</h2>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;" border="0">
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/simsum_pg.png" alt="Plan-guided SIMSUM pipeline">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Document-Level Text Simplification</h3><br>
              <em>Two-stage plan-guided transformer</em><br><br>
              <a href="https://github.com/AtharvRN/document_simplification">GitHub</a>
              <p>
                Designed a plan→generate pipeline in which a RoBERTa planner labels each sentence with copy/rephrase/split/delete operations using surrounding context, then feeds the tags into SIMSUM’s summarizer→simplifier stack. Training on R‑Wiki-Auto (12k docs) with curriculum scheduling, the model delivered SARI 43.56 / D-SARI 38.52 and held up on the out-of-domain PLABA medical corpus.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/dino1.png" alt="DINO training diagnostics" style="margin-bottom:10px;max-width:100%;"><br>
              <img class="project-image" src="images/dino2.png" alt="DINO embedding visualization" style="max-width:100%;">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Exploring Self-Supervised Learning with DINO</h3><br>
              <em>Self-distillation · Representation learning</em><br><br>
              <a href="https://github.com/AtharvRN/EE6380_Project">GitHub</a>
              <p>
                Reimplemented DINO’s student–teacher self-distillation with momentum encoders, multi-crop augmentations, and moving-average diagnostics on Imagenette. The distilled backbone exceeded supervised ResNet/Vision Transformer baselines by 12–20% top-1 accuracy, and its frozen features transfer cleanly to CIFAR-10/100 classification and Pascal VOC segmentation.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/ofdm.png" alt="OFDM channel estimation architecture">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Deep Learning for OFDM Channel Estimation</h3><br>
              <em>Wireless communication · Model compression</em><br><br>
              <a href="https://github.com/AtharvRN/Deep-Learning-based-Channel-Estimation--OFDM">GitHub</a>
              <p>
                Modeled a 64-subcarrier, 16-QAM OFDM link end-to-end—pilot insertion ((3+3j) comb pattern), channel simulation, and demapper—and benchmarked classical LS/MMSE estimators against a skip-connected CNN that outputs 64×2 complex taps. The learned model closes much of the MMSE gap at low SNR while significantly outperforming LS, all within a lightweight PyTorch training loop.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/denoising_report.png" alt="Image denoising report cover">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>Comprehensive Review of Image Denoising</h3><br>
              <em>Classical + deep pipelines</em><br><br>
              <a href="https://github.com/AtharvRN/image_denoising_project">GitHub</a>
              <p>
                Benchmarked wavelet, NLM, BM3D, and WNNM pipelines against autoencoder, DnCNN, RIDNet, CBDNet, and PRIDNet implementations on BSD400/CBSD68 (noise15 &amp; noise25). Architectural tweaks—LeakyReLU activations, dropout, and cascaded enhancement attention—pushed RIDNet to SSIM 0.937 / 0.828, highlighting when classical priors still win and where deep residual learning shines.
              </p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px 0;width:30%;vertical-align:middle;min-width:120px">
              <img class="project-image" src="images/drone_control.png" alt="Drone control system diagram">
            </td>
            <td style="padding:20px 0 20px 40px;width:70%;vertical-align:middle">
              <h3>PID Control of Drone with Overhead Vision</h3><br>
              <em>Robotics club · Real-time control</em><br><br>
              <a href="https://github.com/AtharvRN/drone_control">GitHub</a>
              <p>
                Authored a Python SDK around the Pluto drone’s UDP protocol (ARM/BOXARM/SET_ATTITUDE) with interchangeable Xbox/keyboard teleop, then layered calibrated ArUco pose estimation for overhead feedback. Cropping the detection ROI to 300×300 shrank compute by 95.7%, letting PID loops run fast enough to hold course during Inter IIT drone swarm trials.
              </p>
            </td>
          </tr>
        </table>

        

        <br><br><br><br><hr><br>
        <table border="0" style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0;width:100%;text-align:right">
              <p style="font-size:small;">
                Inspired by <a href="https://github.com/chengxuxin/chengxuxin.github.io">chengxuxin</a> · Original template by <a href="https://jonbarron.info">Jon Barron</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>
</html>
