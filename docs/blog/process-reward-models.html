<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Operationalizing Process Reward Models — Atharv Nair</title>
    <meta
      name="description"
      content="Lessons from fine-tuning DreamPRM-style process reward models for Lean4 theorem proving workloads."
    />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="../style.css" />
    <link rel="icon" type="image/png" href="../assets/profile.png" />
  </head>
  <body>
    <header class="site-header">
      <nav class="nav">
        <a class="brand" href="../">Atharv Nair</a>
        <button class="nav-toggle" aria-label="Toggle navigation">
          <span></span>
          <span></span>
          <span></span>
        </button>
        <ul class="nav-links">
          <li><a href="../#about">About</a></li>
          <li><a href="../#experience">Experience</a></li>
          <li><a href="../#projects">Projects</a></li>
          <li><a href="../#publications">Publications</a></li>
          <li><a href="./">Blog</a></li>
          <li><a href="../#contact">Contact</a></li>
        </ul>
      </nav>
      <section class="section">
        <div class="section-heading">
          <h1>Operationalizing Process Reward Models</h1>
          <p class="footnote">September 2024 · 6 minute read</p>
        </div>
      </section>
    </header>

    <main class="section">
      <article class="publication-card">
        <p>
          Process reward models (PRMs) are a powerful way to steer long-horizon
          reasoning without retraining a base language model end-to-end. Over
          the past few months I applied DreamPRM-style annotation and fine-tuning
          to Lean4 theorem proving workloads. The goal was to raise solve rates
          for a constrained, high-signal domain while keeping inference budgets
          tight.
        </p>
        <h3>Labeling strategy</h3>
        <p>
          We built a token-level labeling pipeline that scores each proof step
          as positive, neutral, or negative based on a lightweight symbolic
          checker. The checker catches common failure signatures—looping,
          vacuous steps, and contradictions—so we could bias the PRM to spot
          dead ends earlier.
        </p>
        <h3>Training setup</h3>
        <p>
          The PRM was fine-tuned with LoRA on top of Llama-3.2 3B. We used
          rank-32 adapters, a cosine scheduler, and switched to mixed precision
          once gradient spikes stabilized. Training ran on Nautilus A100s via
          Kubernetes jobs, with NCCL data parallelism and periodic evaluation
          hooks writing back to Weights &amp; Biases.
        </p>
        <h3>Inference integration</h3>
        <p>
          The PRM scores each candidate proof step and filters out low-confidence
          branches. We combine the PRM signal with an entropy heuristic to
          balance exploration. Result: +9% solve rate, with a 17% reduction in
          average tokens generated per successful proof.
        </p>
        <p>
          The accompanying repository includes manifests, logging utilities,
          and a reference implementation of the scorer:
          <a href="https://github.com/AtharvRN/refound_finetuning" target="_blank" rel="noopener"
            >github.com/AtharvRN/refound_finetuning</a
          >.
        </p>
        <p>
          Questions, suggestions, or similar workloads? I am always happy to
          collaborate.
        </p>
      </article>
    </main>

    <footer class="site-footer">
      <div class="footer-content">
        <h2>Continue exploring</h2>
        <ul class="contact-links">
          <li><a href="./">Back to Notes</a></li>
          <li>
            <a href="mailto:atharv.ramesh2003@gmail.com">Email Atharv</a>
          </li>
          <li>
            <a href="https://www.linkedin.com/in/Atharv-Ramesh" target="_blank" rel="noopener"
              >LinkedIn</a
            >
          </li>
        </ul>
        <p class="footnote">
          &copy; <span id="year"></span> Atharv Nair.
        </p>
      </div>
    </footer>

    <script>
      const nav = document.querySelector(".nav");
      const toggle = document.querySelector(".nav-toggle");
      const links = document.querySelector(".nav-links");

      toggle?.addEventListener("click", () => {
        links.classList.toggle("is-open");
        nav.classList.toggle("is-open");
      });

      document.querySelectorAll(".nav-links a").forEach((anchor) => {
        anchor.addEventListener("click", () => {
          links.classList.remove("is-open");
          nav.classList.remove("is-open");
        });
      });

      document.getElementById("year").textContent = new Date().getFullYear();
    </script>
  </body>
</html>
